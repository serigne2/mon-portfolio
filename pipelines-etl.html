<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Développement de pipelines ETL automatisés</title>
    <link rel="stylesheet" href="css/style.css">  <!-- Lien vers le fichier CSS -->
</head>
<body>
    <header>
        <h1>Développement de pipelines ETL automatisés</h1>
    </header>

    <!-- Section Détails du service -->
    <section>
        <h2>Détails du service</h2>
        <p>Je propose des solutions complètes de développement de pipelines ETL (Extract, Transform, Load) automatisés pour collecter, transformer, et charger efficacement les données dans vos systèmes de stockage ou d'analyse.</p>
        <ul>
            <li>Automatisation des processus de collecte de données depuis différentes sources (bases de données, API, fichiers CSV, etc.)</li>
            <li>Transformation des données pour les rendre exploitables et adaptées aux besoins métier</li>
            <li>Chargement des données dans des entrepôts ou des lacs de données (Amazon Redshift, Google BigQuery, etc.)</li>
        </ul>
    </section>

    <!-- Détail 1 : Exemple de projet ETL -->
    <section>
        <h2>Étude de cas : Pipeline ETL pour une entreprise e-commerce</h2>
        <p>Dans ce projet, j'ai développé un pipeline ETL automatisé pour une plateforme e-commerce, permettant de synchroniser les données des ventes en temps réel et de les charger dans un Data Warehouse pour analyse.</p>
        <ul>
            <li><strong>Sources de données :</strong> Bases de données MySQL et API de partenaires.</li>
            <li><strong>Transformation :</strong> Agrégation des données des ventes, nettoyage des doublons et formatage pour analyse.</li>
            <li><strong>Chargement :</strong> Données chargées dans Amazon Redshift pour des analyses en temps réel via des tableaux de bord.</li>
        </ul>
        <p>Le pipeline a permis une mise à jour continue des données, réduisant les erreurs et le temps de traitement manuel, tout en offrant des analyses rapides aux équipes marketing et commerciales.</p>
    </section>

    <!-- Détail 2 : Technologies utilisées -->
    <section>
        <h2>Technologies que j'utilise pour les pipelines ETL</h2>
        <p>Pour développer des pipelines ETL robustes et automatisés, j'utilise les technologies suivantes :</p>
        <ul>
            <li><strong>Orchestration des workflows :</strong> Apache Airflow, AWS Step Functions</li>
            <li><strong>Transformation des données :</strong> AWS Glue, Databricks, Apache Spark</li>
            <li><strong>Stockage des données :</strong> Amazon S3, Google Cloud Storage, Azure Data Lake</li>
            <li><strong>Chargement :</strong> Amazon Redshift, Google BigQuery, Snowflake</li>
        </ul>
    </section>

    <!-- Lien retour à la page principale -->
    <a href="index.html">Retour à la page principale</a>

    <!-- Scripts (si nécessaires) -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>
</html>
